{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07c57479",
   "metadata": {},
   "source": [
    "# Agents with Human-in-the-Loop\n",
    "\n",
    "We have an email assistant that uses a router to triage emails and then passes the email to the agent for response generation. We've also evaluated it. But do we fully *trust* it to manage our inbox autonomously? For such a sensitive task, human-in-the-loop (HITL) is important! Here we'll show how to add a human-in-the-loop to our email assistant so that we can review specific tool calls. \n",
    "\n",
    "![overview-img](img/overview_hitl.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f73f12",
   "metadata": {},
   "source": [
    "We're going to show how to make the graph *pause* at specific points and await human input.\n",
    "\n",
    "![overview-img](img/hitl_schematic.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e3532e",
   "metadata": {},
   "source": [
    "#### Load Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a57594a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2566464d",
   "metadata": {},
   "source": [
    "## Adding HITL to our email assistant\n",
    "\n",
    "Let's add HITL to our email assistant. \n",
    "\n",
    "We can start with tools, just as we did before. \n",
    "\n",
    "But now, we'll add a new tool Question that allows the assistant to ask the user a question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d4dfb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from typing import Literal\n",
    "from datetime import datetime\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import interrupt, Command\n",
    "\n",
    "from email_assistant.prompts import triage_system_prompt, triage_user_prompt, agent_system_prompt_hitl, default_background, default_triage_instructions, default_response_preferences, default_cal_preferences\n",
    "from email_assistant.tools.default.prompt_templates import HITL_TOOLS_PROMPT\n",
    "from email_assistant.schemas import State, RouterSchema, StateInput\n",
    "from email_assistant.utils import parse_email, format_for_display, format_email_markdown\n",
    "\n",
    "# Agent tools \n",
    "@tool\n",
    "def write_email(to: str, subject: str, content: str) -> str:\n",
    "    \"\"\"Write and send an email.\"\"\"\n",
    "    # Placeholder response - in real app would send email\n",
    "    return f\"Email sent to {to} with subject '{subject}' and content: {content}\"\n",
    "\n",
    "@tool\n",
    "def schedule_meeting(\n",
    "    attendees: list[str], subject: str, duration_minutes: int, preferred_day: datetime, start_time: int\n",
    ") -> str:\n",
    "    \"\"\"Schedule a calendar meeting.\"\"\"\n",
    "    # Placeholder response - in real app would check calendar and schedule\n",
    "    date_str = preferred_day.strftime(\"%A, %B %d, %Y\")\n",
    "    return f\"Meeting '{subject}' scheduled on {date_str} at {start_time} for {duration_minutes} minutes with {len(attendees)} attendees\"\n",
    "\n",
    "@tool\n",
    "def check_calendar_availability(day: str) -> str:\n",
    "    \"\"\"Check calendar availability for a given day.\"\"\"\n",
    "    # Placeholder response - in real app would check actual calendar\n",
    "    return f\"Available times on {day}: 9:00 AM, 2:00 PM, 4:00 PM\"\n",
    "\n",
    "@tool\n",
    "# This is new! \n",
    "class Question(BaseModel):\n",
    "      \"\"\"Question to ask user.\"\"\"\n",
    "      content: str\n",
    "    \n",
    "@tool\n",
    "class Done(BaseModel):\n",
    "      \"\"\"E-mail has been sent.\"\"\"\n",
    "      done: bool\n",
    "\n",
    "# All tools available to the agent\n",
    "tools = [\n",
    "    write_email, \n",
    "    schedule_meeting, \n",
    "    check_calendar_availability, \n",
    "    Question, \n",
    "    Done,\n",
    "]\n",
    "\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "# Initialize the LLM for use with router / structured output\n",
    "llm = init_chat_model(\"openai:gpt-4.1\", temperature=0.0)\n",
    "llm_router = llm.with_structured_output(RouterSchema) \n",
    "\n",
    "# Initialize the LLM, enforcing tool use (of any available tools) for agent\n",
    "llm = init_chat_model(\"openai:gpt-4.1\", temperature=0.0)\n",
    "llm_with_tools = llm.bind_tools(tools, tool_choice=\"required\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf05b260-9809-4f32-807b-abe1632e4181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span>write_email(to, subject, content) - Send emails to specified recipients                                         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span>schedule_meeting(attendees, subject, duration_minutes, preferred_day, start_time) - Schedule calendar meetings  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>where preferred_day is a datetime object                                                                        \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 3 </span>check_calendar_availability(day) - Check available time slots for a given day                                   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 4 </span>Question(content) - Ask the user any follow-up questions                                                        \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 5 </span>Done - E-mail has been sent                                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;33m 1 \u001b[0mwrite_email(to, subject, content) - Send emails to specified recipients                                         \n",
       "\u001b[1;33m 2 \u001b[0mschedule_meeting(attendees, subject, duration_minutes, preferred_day, start_time) - Schedule calendar meetings  \n",
       "\u001b[1;33m   \u001b[0mwhere preferred_day is a datetime object                                                                        \n",
       "\u001b[1;33m 3 \u001b[0mcheck_calendar_availability(day) - Check available time slots for a given day                                   \n",
       "\u001b[1;33m 4 \u001b[0mQuestion(content) - Ask the user any follow-up questions                                                        \n",
       "\u001b[1;33m 5 \u001b[0mDone - E-mail has been sent                                                                                     \n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rich.markdown import Markdown\n",
    "Markdown(HITL_TOOLS_PROMPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f8f334",
   "metadata": {},
   "source": [
    "#### Triage node\n",
    "\n",
    "We define a python function with our triage routing logic, just as we did before.\n",
    "\n",
    "But, if the classification is `notify`, we want to interrupt the graph to allow the user to review the email! \n",
    "\n",
    "So we go to a new node, `triage_interrupt_handler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65efb689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triage_router(state: State) -> Command[Literal[\"triage_interrupt_handler\", \"response_agent\", \"__end__\"]]:\n",
    "    \"\"\"Analyze email content to decide if we should respond, notify, or ignore.\"\"\"\n",
    "\n",
    "    # Parse the email input\n",
    "    author, to, subject, email_thread = parse_email(state[\"email_input\"])\n",
    "    user_prompt = triage_user_prompt.format(\n",
    "        author=author, to=to, subject=subject, email_thread=email_thread\n",
    "    )\n",
    "\n",
    "    # Create email markdown for Agent Inbox in case of notification  \n",
    "    email_markdown = format_email_markdown(subject, author, to, email_thread)\n",
    "\n",
    "    # Format system prompt with background and triage instructions\n",
    "    system_prompt = triage_system_prompt.format(\n",
    "        background=default_background,\n",
    "        triage_instructions=default_triage_instructions\n",
    "    )\n",
    "\n",
    "    # Run the router LLM\n",
    "    result = llm_router.invoke(\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Decision\n",
    "    classification = result.classification\n",
    "\n",
    "    # Process the classification decision\n",
    "    if classification == \"respond\":\n",
    "        print(\"ðŸ“§ Classification: RESPOND - This email requires a response\")\n",
    "        # Next node\n",
    "        goto = \"response_agent\"\n",
    "        # Update the state\n",
    "        update = {\n",
    "            \"classification_decision\": classification,\n",
    "            \"messages\": [{\"role\": \"user\",\n",
    "                            \"content\": f\"Respond to the email: {email_markdown}\"\n",
    "                        }],\n",
    "        }\n",
    "    elif classification == \"ignore\":\n",
    "        print(\"ðŸš« Classification: IGNORE - This email can be safely ignored\")\n",
    "        # Next node\n",
    "        goto = END\n",
    "        # Update the state\n",
    "        update = {\n",
    "            \"classification_decision\": classification,\n",
    "        }\n",
    "\n",
    "    elif classification == \"notify\":\n",
    "        print(\"ðŸ”” Classification: NOTIFY - This email contains important information\") \n",
    "        # This is new! \n",
    "        goto = \"triage_interrupt_handler\"\n",
    "        # Update the state\n",
    "        update = {\n",
    "            \"classification_decision\": classification,\n",
    "        }\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid classification: {classification}\")\n",
    "    return Command(goto=goto, update=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1f564a",
   "metadata": {},
   "source": [
    "#### Triage Interrupt Handler\n",
    "\n",
    "If the decision is to `notify` the user, we interrupt the graph! \n",
    "\n",
    "![overview-img](img/HITL_flow_triage.png)\n",
    "\n",
    "For this, we add a new node, `triage_interrupt_handler`, that will: \n",
    "\n",
    "1. Show the classification to the user if it is `notify`: We'll pass a `dict` to the interrupt that contains our classification. \n",
    "2. Allow the user to respond to the decision: We'll design the code to handle what we will get back from Agent Inbox. \n",
    "\n",
    "As you can see [here](https://github.com/langchain-ai/agent-inbox?tab=readme-ov-file#what-do-the-fields-mean), we format our interrupt with specific fields so that it can be viewed in Agent Inbox:\n",
    "\n",
    "* `action_request`: The action and arguments for the interrupt with `action` (the action name) and `args` (the tool call arguments). This is rendered in the Agent Inbox as the main header for the interrupt event.\n",
    "* `config`: Configures which interaction types are allowed, and specific UI elements for each. \n",
    "* `description`: Should be detailed, and may be markdown. This will be rendered in the Agent Inbox as the description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "203346bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triage_interrupt_handler(state: State) -> Command[Literal[\"response_agent\", \"__end__\"]]:\n",
    "    \"\"\"Handles interrupts from the triage step.\"\"\"\n",
    "    \n",
    "    # Parse the email input\n",
    "    author, to, subject, email_thread = parse_email(state[\"email_input\"])\n",
    "\n",
    "    # Create email markdown for Agent Inbox in case of notification  \n",
    "    email_markdown = format_email_markdown(subject, author, to, email_thread)\n",
    "\n",
    "    # Create messages\n",
    "    messages = [{\"role\": \"user\",\n",
    "                \"content\": f\"Email to notify user about: {email_markdown}\"\n",
    "                }]\n",
    "\n",
    "    # Create interrupt that is shown to the user\n",
    "    request = {\n",
    "        \"action_request\": {\n",
    "            \"action\": f\"Email Assistant: {state['classification_decision']}\",\n",
    "            \"args\": {}\n",
    "        },\n",
    "        \"config\": {\n",
    "            \"allow_ignore\": True,  \n",
    "            \"allow_respond\": True, \n",
    "            \"allow_edit\": False, \n",
    "            \"allow_accept\": False,  \n",
    "        },\n",
    "        # Email to show in Agent Inbox\n",
    "        \"description\": email_markdown,\n",
    "    }\n",
    "\n",
    "    # Agent Inbox responds with a list of dicts with a single key `type` that can be `accept`, `edit`, `ignore`, or `response`.  \n",
    "    response = interrupt([request])[0]\n",
    "\n",
    "    # If user provides feedback, go to response agent and use feedback to respond to email   \n",
    "    if response[\"type\"] == \"response\":\n",
    "        # Add feedback to messages \n",
    "        user_input = response[\"args\"]\n",
    "        # Used by the response agent\n",
    "        messages.append({\"role\": \"user\",\n",
    "                        \"content\": f\"User wants to reply to the email. Use this feedback to respond: {user_input}\"\n",
    "                        })\n",
    "        # Go to response agent\n",
    "        goto = \"response_agent\"\n",
    "\n",
    "    # If user ignores email, go to END\n",
    "    elif response[\"type\"] == \"ignore\":\n",
    "        goto = END\n",
    "\n",
    "    # Catch all other responses\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid response: {response}\")\n",
    "\n",
    "    # Update the state \n",
    "    update = {\n",
    "        \"messages\": messages,\n",
    "    }\n",
    "\n",
    "    return Command(goto=goto, update=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8613e4c4",
   "metadata": {},
   "source": [
    "#### LLM call\n",
    "\n",
    "The `llm_call` node is the same as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "036aba96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_call(state: State):\n",
    "    \"\"\"LLM decides whether to call a tool or not.\"\"\"\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            llm_with_tools.invoke(\n",
    "                [\n",
    "                    {\"role\": \"system\", \"content\": agent_system_prompt_hitl.format(tools_prompt=HITL_TOOLS_PROMPT, \n",
    "                                                                                  background=default_background,\n",
    "                                                                                  response_preferences=default_response_preferences, \n",
    "                                                                                  cal_preferences=default_cal_preferences)}\n",
    "                ]\n",
    "                + state[\"messages\"]\n",
    "            )\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397516ee",
   "metadata": {},
   "source": [
    "#### Interrupt Handler\n",
    "\n",
    "The `interrupt_handler` is the core HITL component of our response agent. \n",
    "\n",
    "Its job is to examine the tool calls that the LLM wants to make and determine which ones need human review before execution. Here's how it works:\n",
    "\n",
    "1. **Tool Selection**: The handler maintains a list of \"HITL tools\" that require human approval:\n",
    "   - `write_email`: Since sending emails has significant external impact\n",
    "   - `schedule_meeting`: Since scheduling meetings affects calendars\n",
    "   - `Question`: Since asking users questions requires direct interaction\n",
    "\n",
    "2. **Direct Execution**: Tools not in the HITL list (like `check_calendar_availability`) are executed immediately without interruption. This allows low-risk operations to proceed automatically.\n",
    "\n",
    "3. **Context Preparation**: For tools requiring review, the handler:\n",
    "   - Retrieves the original email for context\n",
    "   - Formats the tool call details for clear display\n",
    "   - Configures which interaction types are allowed for each tool type\n",
    "\n",
    "4. **Interrupt Creation**: The handler creates a structured interrupt request with:\n",
    "   - The action name and arguments\n",
    "   - Configuration for allowed interaction types\n",
    "   - A description that includes both the original email and the proposed action\n",
    "\n",
    "5. **Response Processing**: After the interrupt, the handler processes the human response:\n",
    "   - **Accept**: Executes the tool with original arguments\n",
    "   - **Edit**: Updates the tool call with edited arguments and then executes\n",
    "   - **Ignore**: Cancels the tool execution\n",
    "   - **Response**: Records feedback without execution\n",
    "\n",
    "This handler ensures humans have oversight of all significant actions while allowing routine operations to proceed automatically. \n",
    "\n",
    "The ability to edit tool arguments (like email content or meeting details) gives users precise control over the assistant's actions.\n",
    "\n",
    "We can visualize the overall flow: \n",
    "\n",
    "![overview-img](img/HITL_flow.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f41929d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interrupt_handler(state: State) -> Command[Literal[\"llm_call\", \"__end__\"]]:\n",
    "    \"\"\"Creates an interrupt for human review of tool calls\"\"\"\n",
    "    \n",
    "    # Store messages\n",
    "    result = []\n",
    "\n",
    "    # Go to the LLM call node next\n",
    "    goto = \"llm_call\"\n",
    "\n",
    "    # Iterate over the tool calls in the last message\n",
    "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
    "        \n",
    "        # Allowed tools for HITL\n",
    "        hitl_tools = [\"write_email\", \"schedule_meeting\", \"Question\"]\n",
    "        \n",
    "        # If tool is not in our HITL list, execute it directly without interruption\n",
    "        if tool_call[\"name\"] not in hitl_tools:\n",
    "\n",
    "            # Execute tool without interruption\n",
    "            tool = tools_by_name[tool_call[\"name\"]]\n",
    "            observation = tool.invoke(tool_call[\"args\"])\n",
    "            result.append({\"role\": \"tool\", \"content\": observation, \"tool_call_id\": tool_call[\"id\"]})\n",
    "            continue\n",
    "            \n",
    "        # Get original email from email_input in state\n",
    "        email_input = state[\"email_input\"]\n",
    "        author, to, subject, email_thread = parse_email(email_input)\n",
    "        original_email_markdown = format_email_markdown(subject, author, to, email_thread)\n",
    "        \n",
    "        # Format tool call for display and prepend the original email\n",
    "        tool_display = format_for_display(tool_call)\n",
    "        description = original_email_markdown + tool_display\n",
    "\n",
    "        # Configure what actions are allowed in Agent Inbox\n",
    "        if tool_call[\"name\"] == \"write_email\":\n",
    "            config = {\n",
    "                \"allow_ignore\": True,\n",
    "                \"allow_respond\": True,\n",
    "                \"allow_edit\": True,\n",
    "                \"allow_accept\": True,\n",
    "            }\n",
    "        elif tool_call[\"name\"] == \"schedule_meeting\":\n",
    "            config = {\n",
    "                \"allow_ignore\": True,\n",
    "                \"allow_respond\": True,\n",
    "                \"allow_edit\": True,\n",
    "                \"allow_accept\": True,\n",
    "            }\n",
    "        elif tool_call[\"name\"] == \"Question\":\n",
    "            config = {\n",
    "                \"allow_ignore\": True,\n",
    "                \"allow_respond\": True,\n",
    "                \"allow_edit\": False,\n",
    "                \"allow_accept\": False,\n",
    "            }\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid tool call: {tool_call['name']}\")\n",
    "\n",
    "        # Create the interrupt request\n",
    "        request = {\n",
    "            \"action_request\": {\n",
    "                \"action\": tool_call[\"name\"],\n",
    "                \"args\": tool_call[\"args\"]\n",
    "            },\n",
    "            \"config\": config,\n",
    "            \"description\": description,\n",
    "        }\n",
    "\n",
    "        # Send to Agent Inbox and wait for response\n",
    "        response = interrupt([request])[0]\n",
    "\n",
    "        # Handle the responses \n",
    "        if response[\"type\"] == \"accept\":\n",
    "\n",
    "            # Execute the tool with original args\n",
    "            tool = tools_by_name[tool_call[\"name\"]]\n",
    "            observation = tool.invoke(tool_call[\"args\"])\n",
    "            result.append({\"role\": \"tool\", \"content\": observation, \"tool_call_id\": tool_call[\"id\"]})\n",
    "                        \n",
    "        elif response[\"type\"] == \"edit\":\n",
    "\n",
    "            # Tool selection \n",
    "            tool = tools_by_name[tool_call[\"name\"]]\n",
    "            \n",
    "            # Get edited args from Agent Inbox\n",
    "            edited_args = response[\"args\"][\"args\"]\n",
    "\n",
    "            # Update the AI message's tool call with edited content (reference to the message in the state)\n",
    "            ai_message = state[\"messages\"][-1] # Get the most recent message from the state\n",
    "            current_id = tool_call[\"id\"] # Store the ID of the tool call being edited\n",
    "            \n",
    "            # Create a new list of tool calls by filtering out the one being edited and adding the updated version\n",
    "            # This avoids modifying the original list directly (immutable approach)\n",
    "            updated_tool_calls = [tc for tc in ai_message.tool_calls if tc[\"id\"] != current_id] + [\n",
    "                {\"type\": \"tool_call\", \"name\": tool_call[\"name\"], \"args\": edited_args, \"id\": current_id}\n",
    "            ]\n",
    "            \n",
    "            # Create a new copy of the message with updated tool calls rather than modifying the original\n",
    "            # This ensures state immutability and prevents side effects in other parts of the code\n",
    "            # When we update the messages state key (\"messages\": result), the add_messages reducer will\n",
    "            # overwrite existing messages by id and we take advantage of this here to update the tool calls.\n",
    "            result.append(ai_message.model_copy(update={\"tool_calls\": updated_tool_calls}))\n",
    "\n",
    "            # Update the write_email tool call with the edited content from Agent Inbox\n",
    "            if tool_call[\"name\"] == \"write_email\":\n",
    "                \n",
    "                # Execute the tool with edited args\n",
    "                observation = tool.invoke(edited_args)\n",
    "                \n",
    "                # Add only the tool response message\n",
    "                result.append({\"role\": \"tool\", \"content\": observation, \"tool_call_id\": current_id})\n",
    "            \n",
    "            # Update the schedule_meeting tool call with the edited content from Agent Inbox\n",
    "            elif tool_call[\"name\"] == \"schedule_meeting\":\n",
    "                \n",
    "                \n",
    "                # Execute the tool with edited args\n",
    "                observation = tool.invoke(edited_args)\n",
    "                \n",
    "                # Add only the tool response message\n",
    "                result.append({\"role\": \"tool\", \"content\": observation, \"tool_call_id\": current_id})\n",
    "            \n",
    "            # Catch all other tool calls\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid tool call: {tool_call['name']}\")\n",
    "\n",
    "        elif response[\"type\"] == \"ignore\":\n",
    "            if tool_call[\"name\"] == \"write_email\":\n",
    "                # Don't execute the tool, and tell the agent how to proceed\n",
    "                result.append({\"role\": \"tool\", \"content\": \"User ignored this email draft. Ignore this email and end the workflow.\", \"tool_call_id\": tool_call[\"id\"]})\n",
    "                # Go to END\n",
    "                goto = END\n",
    "            elif tool_call[\"name\"] == \"schedule_meeting\":\n",
    "                # Don't execute the tool, and tell the agent how to proceed\n",
    "                result.append({\"role\": \"tool\", \"content\": \"User ignored this calendar meeting draft. Ignore this email and end the workflow.\", \"tool_call_id\": tool_call[\"id\"]})\n",
    "                # Go to END\n",
    "                goto = END\n",
    "            elif tool_call[\"name\"] == \"Question\":\n",
    "                # Don't execute the tool, and tell the agent how to proceed\n",
    "                result.append({\"role\": \"tool\", \"content\": \"User ignored this question. Ignore this email and end the workflow.\", \"tool_call_id\": tool_call[\"id\"]})\n",
    "                # Go to END\n",
    "                goto = END\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid tool call: {tool_call['name']}\")\n",
    "            \n",
    "        elif response[\"type\"] == \"response\":\n",
    "            # User provided feedback\n",
    "            user_feedback = response[\"args\"]\n",
    "            if tool_call[\"name\"] == \"write_email\":\n",
    "                # Don't execute the tool, and add a message with the user feedback to incorporate into the email\n",
    "                result.append({\"role\": \"tool\", \"content\": f\"User gave feedback, which can we incorporate into the email. Feedback: {user_feedback}\", \"tool_call_id\": tool_call[\"id\"]})\n",
    "            elif tool_call[\"name\"] == \"schedule_meeting\":\n",
    "                # Don't execute the tool, and add a message with the user feedback to incorporate into the email\n",
    "                result.append({\"role\": \"tool\", \"content\": f\"User gave feedback, which can we incorporate into the meeting request. Feedback: {user_feedback}\", \"tool_call_id\": tool_call[\"id\"]})\n",
    "            elif tool_call[\"name\"] == \"Question\": \n",
    "                # Don't execute the tool, and add a message with the user feedback to incorporate into the email\n",
    "                result.append({\"role\": \"tool\", \"content\": f\"User answered the question, which can we can use for any follow up actions. Feedback: {user_feedback}\", \"tool_call_id\": tool_call[\"id\"]})\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid tool call: {tool_call['name']}\")\n",
    "\n",
    "        # Catch all other responses\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid response: {response}\")\n",
    "            \n",
    "    # Update the state \n",
    "    update = {\n",
    "        \"messages\": result,\n",
    "    }\n",
    "\n",
    "    return Command(goto=goto, update=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164b0897",
   "metadata": {},
   "source": [
    "Now, let's compile the graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b6d1013",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_41/1607184874.py:38: LangGraphDeprecatedSinceV05: `input` is deprecated and will be removed. Please use `input_schema` instead. Deprecated in LangGraph V0.5 to be removed in V2.0.\n",
      "  StateGraph(State, input=StateInput)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from email_assistant.utils import show_graph\n",
    "\n",
    "# Conditional edge function\n",
    "def should_continue(state: State) -> Literal[\"interrupt_handler\", \"__end__\"]:\n",
    "    \"\"\"Route to tool handler, or end if Done tool called\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    if last_message.tool_calls:\n",
    "        for tool_call in last_message.tool_calls: \n",
    "            if tool_call[\"name\"] == \"Done\":\n",
    "                return END\n",
    "            else:\n",
    "                return \"interrupt_handler\"\n",
    "\n",
    "# Build workflow\n",
    "agent_builder = StateGraph(State)\n",
    "\n",
    "# Add nodes\n",
    "agent_builder.add_node(\"llm_call\", llm_call)\n",
    "agent_builder.add_node(\"interrupt_handler\", interrupt_handler)\n",
    "\n",
    "# Add edges\n",
    "agent_builder.add_edge(START, \"llm_call\")\n",
    "agent_builder.add_conditional_edges(\n",
    "    \"llm_call\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"interrupt_handler\": \"interrupt_handler\",\n",
    "        END: END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Compile the agent\n",
    "response_agent = agent_builder.compile()\n",
    "\n",
    "# Build overall workflow\n",
    "overall_workflow = (\n",
    "    StateGraph(State, input=StateInput)\n",
    "    .add_node(triage_router)\n",
    "    .add_node(triage_interrupt_handler)\n",
    "    .add_node(\"response_agent\", response_agent)\n",
    "    .add_edge(START, \"triage_router\")\n",
    "    \n",
    ")\n",
    "\n",
    "email_assistant = overall_workflow.compile()\n",
    "show_graph(email_assistant, xray=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d747dcda",
   "metadata": {},
   "source": [
    "#### Review of HITL Patterns\n",
    "\n",
    "**Triage Interruption** When an email is classified as \"notify\", the system interrupts to show the email to the human user\n",
    "- *User Decision*: User can choose to ignore the notification or provide feedback to respond to the email\n",
    "- *Flow Control*: If ignored, workflow ends; if user provides feedback, it flows to the Response Agent\n",
    "\n",
    "**Write Email**: System shows proposed email draft for human review\n",
    "- *User Decision and Flow Control*: ignore (end workflow), respond with feedback, accept draft as-is, or edit draft\n",
    "\n",
    "**Schedule Meeting**: System shows proposed meeting details for human review\n",
    "- *User Decision and Flow Control*: ignore (end workflow), respond with feedback, accept meeting details as-is, or edit details\n",
    "\n",
    "**Question**: System asks user a question to clarify information\n",
    "- *User Decision and Flow Control*: ignore (end workflow) or respond with an answer\n",
    "\n",
    "### Interrupts Allow Us to Review and Accept Tool Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c12b2097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the graph until the first interrupt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    },
    {
     "ename": "APIConnectionError",
     "evalue": "Connection error.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mConnectError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/app/.venv/lib/python3.11/site-packages/httpx/_transports/default.py:101\u001b[39m, in \u001b[36mmap_httpcore_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/app/.venv/lib/python3.11/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/app/.venv/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/app/.venv/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/app/.venv/lib/python3.11/site-packages/httpcore/_sync/connection.py:101\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection.handle_request(request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/app/.venv/lib/python3.11/site-packages/httpcore/_sync/connection.py:78\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     stream = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m     ssl_object = stream.get_extra_info(\u001b[33m\"\u001b[39m\u001b[33mssl_object\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/app/.venv/lib/python3.11/site-packages/httpcore/_sync/connection.py:124\u001b[39m, in \u001b[36mHTTPConnection._connect\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mconnect_tcp\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m     stream = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_backend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect_tcp\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    125\u001b[39m     trace.return_value = stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/app/.venv/lib/python3.11/site-packages/httpcore/_backends/sync.py:207\u001b[39m, in \u001b[36mSyncBackend.connect_tcp\u001b[39m\u001b[34m(self, host, port, timeout, local_address, socket_options)\u001b[39m\n\u001b[32m    202\u001b[39m exc_map: ExceptionMapping = {\n\u001b[32m    203\u001b[39m     socket.timeout: ConnectTimeout,\n\u001b[32m    204\u001b[39m     \u001b[38;5;167;01mOSError\u001b[39;00m: ConnectError,\n\u001b[32m    205\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmap_exceptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc_map\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43msocket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m        \u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m=\u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/contextlib.py:158\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     \u001b[38;5;28mself\u001b[39m.gen.throw(typ, value, traceback)\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    160\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    161\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/app/.venv/lib/python3.11/site-packages/httpcore/_exceptions.py:14\u001b[39m, in \u001b[36mmap_exceptions\u001b[39m\u001b[34m(map)\u001b[39m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mConnectError\u001b[39m: [Errno 101] Network is unreachable",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mConnectError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/app/.venv/lib/python3.11/site-packages/openai/_base_client.py:982\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m    981\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m982\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    987\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/app/.venv/lib/python3.11/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/app/.venv/lib/python3.11/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/app/.venv/lib/python3.11/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/app/.venv/lib/python3.11/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/app/.venv/lib/python3.11/site-packages/httpx/_transports/default.py:249\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmap_httpcore_exceptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresp\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/contextlib.py:158\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     \u001b[38;5;28mself\u001b[39m.gen.throw(typ, value, traceback)\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    160\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    161\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/app/.venv/lib/python3.11/site-packages/httpx/_transports/default.py:118\u001b[39m, in \u001b[36mmap_httpcore_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    117\u001b[39m message = \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mConnectError\u001b[39m: [Errno 101] Network is unreachable",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mAPIConnectionError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Run the graph until a tool call that we choose to interrupt\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRunning the graph until the first interrupt...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43memail_input\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43memail_input_respond\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthread_config_1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Inspect interrupt object if present\u001b[39;49;00m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m__interrupt__\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m        \u001b[49m\u001b[43mInterrupt_Object\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m__interrupt__\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/app/.venv/lib/python3.11/site-packages/langgraph/pregel/main.py:2679\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2677\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2678\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2679\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2680\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2681\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2682\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2683\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2684\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2685\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2686\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2687\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2688\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2689\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/app/.venv/lib/python3.11/site-packages/langgraph/pregel/_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/app/.venv/lib/python3.11/site-packages/langgraph/pregel/_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/app/.venv/lib/python3.11/site-packages/langgraph/_internal/_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/app/.venv/lib/python3.11/site-packages/langgraph/_internal/_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mtriage_router\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     14\u001b[39m system_prompt = triage_system_prompt.format(\n\u001b[32m     15\u001b[39m     background=default_background,\n\u001b[32m     16\u001b[39m     triage_instructions=default_triage_instructions\n\u001b[32m     17\u001b[39m )\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Run the router LLM\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m result = \u001b[43mllm_router\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msystem\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_prompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Decision\u001b[39;00m\n\u001b[32m     28\u001b[39m classification = result.classification\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/app/.venv/lib/python3.11/site-packages/langchain_core/runnables/base.py:3091\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3089\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   3090\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m3091\u001b[39m         input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3092\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3093\u001b[39m         input_ = context.run(step.invoke, input_, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/app/.venv/lib/python3.11/site-packages/langchain_core/runnables/base.py:5492\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5485\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5486\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5487\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5490\u001b[39m     **kwargs: Any | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   5491\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5492\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5493\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5494\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5495\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5496\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/app/.venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:379\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    365\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    366\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    367\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    372\u001b[39m     **kwargs: Any,\n\u001b[32m    373\u001b[39m ) -> AIMessage:\n\u001b[32m    374\u001b[39m     config = ensure_config(config)\n\u001b[32m    375\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    376\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    377\u001b[39m         cast(\n\u001b[32m    378\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m379\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    389\u001b[39m         ).message,\n\u001b[32m    390\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/app/.venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:1088\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1079\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1080\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1081\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1085\u001b[39m     **kwargs: Any,\n\u001b[32m   1086\u001b[39m ) -> LLMResult:\n\u001b[32m   1087\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1088\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/app/.venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:903\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    900\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    901\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    902\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m903\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    904\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    905\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    906\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    907\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    908\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    909\u001b[39m         )\n\u001b[32m    910\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    911\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/app/.venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:1192\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1190\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1191\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1192\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1196\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/app/.venv/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1299\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1297\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m raw_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(raw_response, \u001b[33m\"\u001b[39m\u001b[33mhttp_response\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1298\u001b[39m         e.response = raw_response.http_response  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1299\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   1300\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1301\u001b[39m     \u001b[38;5;28mself\u001b[39m.include_response_headers\n\u001b[32m   1302\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m raw_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1303\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(raw_response, \u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1304\u001b[39m ):\n\u001b[32m   1305\u001b[39m     generation_info = {\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response.headers)}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/app/.venv/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1267\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1264\u001b[39m payload.pop(\u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1265\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1266\u001b[39m     raw_response = (\n\u001b[32m-> \u001b[39m\u001b[32m1267\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroot_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_raw_response\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1268\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\n\u001b[32m   1269\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1270\u001b[39m     )\n\u001b[32m   1271\u001b[39m     response = raw_response.parse()\n\u001b[32m   1272\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m openai.BadRequestError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/app/.venv/lib/python3.11/site-packages/openai/_legacy_response.py:364\u001b[39m, in \u001b[36mto_raw_response_wrapper.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    360\u001b[39m extra_headers[RAW_RESPONSE_HEADER] = \u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    362\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mextra_headers\u001b[39m\u001b[33m\"\u001b[39m] = extra_headers\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(LegacyAPIResponse[R], \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/app/.venv/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py:183\u001b[39m, in \u001b[36mCompletions.parse\u001b[39m\u001b[34m(self, messages, model, audio, response_format, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, safety_identifier, seed, service_tier, stop, store, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparser\u001b[39m(raw_completion: ChatCompletion) -> ParsedChatCompletion[ResponseFormatT]:\n\u001b[32m    177\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _parse_chat_completion(\n\u001b[32m    178\u001b[39m         response_format=response_format,\n\u001b[32m    179\u001b[39m         chat_completion=raw_completion,\n\u001b[32m    180\u001b[39m         input_tools=chat_completion_tools,\n\u001b[32m    181\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_type_to_response_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    226\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    228\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# we turn the `ChatCompletion` instance into a `ParsedChatCompletion`\u001b[39;49;00m\n\u001b[32m    232\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# in the `parser` function above\u001b[39;49;00m\n\u001b[32m    233\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mType\u001b[49m\u001b[43m[\u001b[49m\u001b[43mParsedChatCompletion\u001b[49m\u001b[43m[\u001b[49m\u001b[43mResponseFormatT\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/app/.venv/lib/python3.11/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/app/.venv/lib/python3.11/site-packages/openai/_base_client.py:1014\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1011\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1013\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mRaising connection error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m APIConnectionError(request=request) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   1016\u001b[39m log.debug(\n\u001b[32m   1017\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mHTTP Response: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m,\n\u001b[32m   1018\u001b[39m     request.method,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     response.headers,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m log.debug(\u001b[33m\"\u001b[39m\u001b[33mrequest_id: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, response.headers.get(\u001b[33m\"\u001b[39m\u001b[33mx-request-id\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[31mAPIConnectionError\u001b[39m: Connection error.",
      "During task with name 'triage_router' and id '32dd3caa-0b47-1598-d6eb-5a2f0be5c5ab'"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "# Email to respond to\n",
    "email_input_respond = {\n",
    "    \"to\": \"Lance Martin <lance@company.com>\",\n",
    "    \"author\": \"Project Manager <pm@client.com>\",\n",
    "    \"subject\": \"Tax season let's schedule call\",\n",
    "    \"email_thread\": \"Lance,\\n\\nIt's tax season again, and I wanted to schedule a call to discuss your tax planning strategies for this year. I have some suggestions that could potentially save you money.\\n\\nAre you available sometime next week? Tuesday or Thursday afternoon would work best for me, for about 45 minutes.\\n\\nRegards,\\nProject Manager\"\n",
    "}\n",
    "\n",
    "# Compile the graph with checkpointer\n",
    "checkpointer = InMemorySaver()\n",
    "graph = overall_workflow.compile(checkpointer=checkpointer)\n",
    "thread_id_1 = uuid.uuid4()\n",
    "thread_config_1 = {\"configurable\": {\"thread_id\": thread_id_1}}\n",
    "\n",
    "# Run the graph until a tool call that we choose to interrupt\n",
    "print(\"Running the graph until the first interrupt...\")\n",
    "for chunk in graph.stream({\"email_input\": email_input_respond}, config=thread_config_1):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5546ad46",
   "metadata": {},
   "source": [
    "What happened? We hit the [interrupt](https://langchain-ai.github.io/langgraph/concepts/interrupts/), which paused execution at the tool call. You can see the `action` (tool call name) and `args` (tool call arguments) that we interrupted displayed to the user.\n",
    "\n",
    "Now, how do we handle the interrupt? This is where the `Command` interface comes in. [The `Command` object has several powerful capabilities](https://langchain-ai.github.io/langgraph/how-tos/command/). We used it to direct the flow of the graph in prior notebooks: \n",
    "- `goto`: Specifies which node to route to next\n",
    "- `update`: Modifies the state before continuing execution\n",
    "\n",
    "Here, we'll use it to resume the graph from the interrupted state:\n",
    "- `resume`: Provides the value to return from the interrupt call\n",
    "\n",
    "We can return whatever value our graph is designed to handle. In our case, the graph is designed to handle a list of dicts with a single key `type` that can be `accept`, `edit`, `ignore`, or `response`. So, we can simply pass `{\"type\": \"accept\"}` to the `resume` argument in order to tell the graph that we accept the tool call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b1f772",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Command\n",
    "\n",
    "print(f\"\\nSimulating user accepting the {Interrupt_Object.value[0]['action_request']} tool call...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"accept\"}]), config=thread_config_1):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd321c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulating user accepting the {Interrupt_Object.value[0]['action_request']} tool call...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"accept\"}]), config=thread_config_1):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77baa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(thread_config_1)\n",
    "for m in state.values['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b1ba30",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Interrupts Allow Us to Edit Tool Calls\n",
    "\n",
    "This test demonstrates how human modification works in the HITL flow:\n",
    "1. We start with the same tax planning email as before\n",
    "2. The agent proposes a meeting with the same parameters\n",
    "3. This time, the user EDITS the meeting proposal to change:\n",
    "   - Duration from 45 to 30 minutes\n",
    "   - Meeting subject is made more concise\n",
    "4. The agent adapts to these changes when drafting the email\n",
    "5. The user further EDITS the email to be shorter and less formal\n",
    "6. The workflow completes with both modifications incorporated\n",
    "\n",
    "This scenario showcases one of the most powerful aspects of HITL: \n",
    "\n",
    "* Users can make precise modifications to agent actions before they are executed, ensuring the final outcome matches their preferences without having to handle all the details themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfca1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same email as before\n",
    "email_input_respond = {\n",
    "    \"to\": \"Lance Martin <lance@company.com>\",\n",
    "    \"author\": \"Project Manager <pm@client.com>\",\n",
    "    \"subject\": \"Tax season let's schedule call\",\n",
    "    \"email_thread\": \"Lance,\\n\\nIt's tax season again, and I wanted to schedule a call to discuss your tax planning strategies for this year. I have some suggestions that could potentially save you money.\\n\\nAre you available sometime next week? Tuesday or Thursday afternoon would work best for me, for about 45 minutes.\\n\\nRegards,\\nProject Manager\"\n",
    "}\n",
    "\n",
    "# Compile the graph with new thread\n",
    "checkpointer = InMemorySaver()\n",
    "graph = overall_workflow.compile(checkpointer=checkpointer)\n",
    "thread_id_2 = uuid.uuid4()\n",
    "thread_config_2 = {\"configurable\": {\"thread_id\": thread_id_2}}\n",
    "\n",
    "# Run the graph until the first interrupt - will be classified as \"respond\" and the agent will create a write_email tool call\n",
    "print(\"Running the graph until the first interrupt...\")\n",
    "for chunk in graph.stream({\"email_input\": email_input_respond}, config=thread_config_2):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706ac0a6",
   "metadata": {},
   "source": [
    "Edit the `schedule_meeting` tool call\n",
    "\n",
    "When the agent proposes the initial meeting schedule, we now simulate the user making modifications through the edit functionality. This demonstrates how the `edit` response type works:\n",
    "\n",
    "1. The user receives the same meeting proposal as in the previous test\n",
    "2. Instead of accepting, they modify the parameters:\n",
    "   - Reducing duration from 45 to 30 minutes\n",
    "   - Keeping the same day and time\n",
    "3. The `edit` response includes the complete set of modified arguments\n",
    "4. The interrupt handler replaces the original tool arguments with these edited ones\n",
    "5. The tool is executed with the user's modifications\n",
    "\n",
    "This shows how edit capability gives users precise control over agent actions while still letting the agent handle the execution details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7175fedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now simulate user editing the schedule_meeting tool call\n",
    "print(\"\\nSimulating user editing the schedule_meeting tool call...\")\n",
    "edited_schedule_args = {\n",
    "    \"attendees\": [\"pm@client.com\", \"lance@company.com\"],\n",
    "    \"subject\": \"Tax Planning Discussion\",\n",
    "    \"duration_minutes\": 30,  # Changed from 45 to 30\n",
    "    \"preferred_day\": \"2025-05-06\",\n",
    "    \"start_time\": 14 \n",
    "}\n",
    "\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"edit\", \"args\": {\"args\": edited_schedule_args}}]), config=thread_config_2):\n",
    "    # Inspect response_agent most recent message\n",
    "    if 'response_agent' in chunk:\n",
    "        chunk['response_agent']['messages'][-1].pretty_print()\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9757706b",
   "metadata": {},
   "source": [
    "Edit the `write_email` tool call\n",
    "\n",
    "After accepting the modified meeting schedule, the agent drafts an email reflecting the 30-minute duration. Now we demonstrate how editing works with email content:\n",
    "\n",
    "1. The agent has adapted its email to mention the shorter 30-minute duration\n",
    "2. We simulate the user wanting an even more significant change to the email:\n",
    "   - Completely rewriting the content to be shorter and less formal\n",
    "   - Changing the meeting day mentioned in the email (showing how users can correct agent mistakes)\n",
    "   - Requesting confirmation rather than stating the meeting as definite\n",
    "3. The `edit` response contains the complete new email content\n",
    "4. The tool arguments are updated with this edited content\n",
    "5. The email is sent with the user's preferred wording\n",
    "\n",
    "This example shows the power of HITL for complex communication tasks - the agent handles the structure and initial content, while humans can refine tone, style, and substance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0604d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now simulate user editing the write_email tool call\n",
    "print(\"\\nSimulating user editing the write_email tool call...\")\n",
    "edited_email_args = {\n",
    "    \"to\": \"pm@client.com\",\n",
    "    \"subject\": \"Re: Tax season let's schedule call\",\n",
    "    \"content\": \"Hello Project Manager,\\n\\nThank you for reaching out about tax planning. I scheduled a 30-minute call next Thursday at 3:00 PM. Would that work for you?\\n\\nBest regards,\\nLance Martin\"\n",
    "}\n",
    "\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"edit\", \"args\": {\"args\": edited_email_args}}]), config=thread_config_2):\n",
    "    # Inspect response_agent most recent message\n",
    "    if 'response_agent' in chunk:\n",
    "        chunk['response_agent']['messages'][-1].pretty_print()\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac279101",
   "metadata": {},
   "source": [
    "Look at the full message history, and see trace, to view the edited tool calls:\n",
    "\n",
    "https://smith.langchain.com/public/21769510-d57a-41e4-b5c7-0ddb23c237d8/r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3e9be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(thread_config_2)\n",
    "for m in state.values['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4c39e9",
   "metadata": {},
   "source": [
    "### Interrupts Allow Us to Provide Feedback on Tool Calls\n",
    "\n",
    "This test set demonstrates the \"response\" capability - providing feedback without editing or accepting:\n",
    "\n",
    "1. First, we test feedback for meeting scheduling:\n",
    "   - The user provides specific preferences (30 minutes instead of 45, and afternoon meetings)\n",
    "   - The agent incorporates this feedback into a revised proposal\n",
    "   - The user then accepts the revised meeting schedule\n",
    "\n",
    "2. Second, we test feedback for email drafting:\n",
    "   - The user requests a shorter, less formal email with a specific closing statement\n",
    "   - The agent completely rewrites the email according to this guidance\n",
    "   - The user accepts the new draft\n",
    "\n",
    "3. Lastly, we test feedback for questions:\n",
    "   - For the brunch invitation, the user answers the question with additional context\n",
    "   - The agent uses this information to draft an appropriate email response\n",
    "   - The workflow proceeds with the user's input integrated\n",
    "\n",
    "The \"response\" capability bridges the gap between acceptance and editing - users can guide the agent without having to write the full content themselves. This is especially powerful for:\n",
    "- Adjusting tone and style\n",
    "- Adding context the agent missed\n",
    "- Redirecting the agent's approach\n",
    "- Answering questions in a way that shapes the next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4b3517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Respond - Meeting Request Email\n",
    "email_input_respond = {\n",
    "    \"to\": \"Lance Martin <lance@company.com>\",\n",
    "    \"author\": \"Project Manager <pm@client.com>\",\n",
    "    \"subject\": \"Tax season let's schedule call\",\n",
    "    \"email_thread\": \"Lance,\\n\\nIt's tax season again, and I wanted to schedule a call to discuss your tax planning strategies for this year. I have some suggestions that could potentially save you money.\\n\\nAre you available sometime next week? Tuesday or Thursday afternoon would work best for me, for about 45 minutes.\\n\\nRegards,\\nProject Manager\"\n",
    "}\n",
    "\n",
    "# Compile the graph\n",
    "checkpointer = InMemorySaver()\n",
    "graph = overall_workflow.compile(checkpointer=checkpointer)\n",
    "thread_id_5 = uuid.uuid4()\n",
    "thread_config_5 = {\"configurable\": {\"thread_id\": thread_id_5}}\n",
    "\n",
    "# Run the graph until the first interrupt \n",
    "# Email will be classified as \"respond\" \n",
    "# Agent will create a schedule_meeting and write_email tool call\n",
    "print(\"Running the graph until the first interrupt...\")\n",
    "for chunk in graph.stream({\"email_input\": email_input_respond}, config=thread_config_5):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2bea0a",
   "metadata": {},
   "source": [
    "Provide feedback for the `schedule_meeting` tool call\n",
    "\n",
    "Now we explore the feedback capability for meeting scheduling:\n",
    "\n",
    "1. The agent proposes the standard 45-minute meeting on Tuesday at 2:00 PM\n",
    "2. Instead of accepting or editing, we provide feedback in natural language\n",
    "3. Our feedback specifies two preferences:\n",
    "   - Shorter meeting (30 minutes instead of 45)\n",
    "   - Preference for afternoon meetings (after 2pm)\n",
    "4. The agent receives this feedback through the `response` type\n",
    "5. The interrupt handler adds this feedback as a message to the state\n",
    "6. The agent processes this feedback and generates a new tool call incorporating these preferences\n",
    "\n",
    "Unlike direct editing, which requires specifying the entire set of parameters, feedback allows users to express their preferences conversationally. The agent must then interpret this feedback and apply it appropriately to create a revised proposal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a916e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulating user providing feedback for the {Interrupt_Object.value[0]['action_request']['action']} tool call...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"response\", \"args\": \"Please schedule this for 30 minutes instead of 45 minutes, and I prefer afternoon meetings after 2pm.\"}]), config=thread_config_5):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf35f1a2",
   "metadata": {},
   "source": [
    "Accept the `schedule_meeting` tool call after providing feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2727fb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulating user accepting the {Interrupt_Object.value[0]['action_request']} tool call...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"accept\"}]), config=thread_config_5):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca470c5",
   "metadata": {},
   "source": [
    "Now provide feedback for the `write_email` tool call\n",
    "\n",
    "After accepting the revised meeting schedule, the agent drafts an email. We now test feedback for email content:\n",
    "\n",
    "1. The agent's email is relatively formal and detailed\n",
    "2. We provide stylistic feedback requesting:\n",
    "   - A shorter, more concise email\n",
    "   - A less formal tone\n",
    "   - A specific closing statement about looking forward to the meeting\n",
    "3. The agent processes this feedback to completely rewrite the email\n",
    "4. The new draft is much shorter, more casual, and includes the requested closing\n",
    "\n",
    "This demonstrates the power of natural language feedback for content creation:\n",
    "- Users don't need to rewrite the entire email themselves\n",
    "- They can provide high-level guidance on style, tone, and content\n",
    "- The agent handles the actual writing based on this guidance\n",
    "- The result better matches user preferences while preserving the essential information\n",
    "\n",
    "The message history shows both the original and revised emails, clearly showing how the feedback was incorporated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5221d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulating user providing feedback for the {Interrupt_Object.value[0]['action_request']['action']} tool call...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"response\", \"args\": \"Shorter and less formal. Include a closing statement about looking forward to the meeting!\"}]), config=thread_config_5):\n",
    "    # Inspect response_agent most recent message\n",
    "    if 'response_agent' in chunk:\n",
    "        chunk['response_agent']['messages'][-1].pretty_print()\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1266ec72",
   "metadata": {},
   "source": [
    "Accept the `write_email` tool call after providing feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4698c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulating user accepting the {Interrupt_Object.value[0]['action_request']} tool call...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"accept\"}]), config=thread_config_5):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c270f52a",
   "metadata": {},
   "source": [
    "Look at the full message history, and see the trace:\n",
    "\n",
    "https://smith.langchain.com/public/57006770-6bb3-4e40-b990-143c373ebe60/r\n",
    "\n",
    "We can see that user feedback in incorporated into the tool calls.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daf10d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(thread_config_5)\n",
    "for m in state.values['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d964e36",
   "metadata": {},
   "source": [
    "### Interrupts Enable New Tools\n",
    "\n",
    "Now let's try an email that calls the `Question` tool to provide feedback\n",
    "\n",
    "Finally, we test how feedback works with the `Question` tool:\n",
    "\n",
    "1. For the brunch invitation email, the agent asks about preferred day and time\n",
    "2. Instead of ignoring, we provide a substantive response with additional context:\n",
    "   - Confirming we want to invite the people mentioned\n",
    "   - Noting we need to check which weekend works best\n",
    "   - Adding information about needing a reservation\n",
    "3. The agent uses this information to:\n",
    "   - Draft a comprehensive email response incorporating all our feedback\n",
    "   - Notice we didn't provide a specific day/time, so it suggests checking the calendar\n",
    "   - Include the detail about making a reservation\n",
    "4. The complete email reflects both the original request and our additional guidance\n",
    "\n",
    "This demonstrates how question responses can shape the entire workflow:\n",
    "- Questions let the agent gather missing information\n",
    "- User responses can include both direct answers and additional context\n",
    "- The agent integrates all this information into its next actions\n",
    "- The final outcome reflects the collaborative intelligence of both human and AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8827632a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Respond\n",
    "email_input_respond = {\n",
    "    \"to\": \"Lance Martin <lance@company.com>\",\n",
    "    \"author\": \"Partner <partner@home.com>\",\n",
    "    \"subject\": \"Dinner?\",\n",
    "    \"email_thread\": \"Hey, do you want italian or indian tonight?\"}\n",
    "\n",
    "# Compile the graph\n",
    "checkpointer = InMemorySaver()\n",
    "graph = overall_workflow.compile(checkpointer=checkpointer)\n",
    "thread_id_6 = uuid.uuid4()\n",
    "thread_config_6 = {\"configurable\": {\"thread_id\": thread_id_6}}\n",
    "\n",
    "# Run the graph until the first interrupt\n",
    "print(\"Running the graph until the first interrupt...\")\n",
    "for chunk in graph.stream({\"email_input\": email_input_respond}, config=thread_config_6):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9f7f1b",
   "metadata": {},
   "source": [
    "Provide feedback for the `Question` tool call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4979effd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulating user providing feedback for the {Interrupt_Object.value[0]['action_request']['action']} tool call...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"response\", \"args\": \"Let's do indian.\"}]), config=thread_config_6):\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b4ba9b",
   "metadata": {},
   "source": [
    "Accept the `write_email` tool call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd34ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSimulating user accepting the {Interrupt_Object.value[0]['action_request']['action']} tool call...\")\n",
    "for chunk in graph.stream(Command(resume=[{\"type\": \"accept\"}]), config=thread_config_6):\n",
    "    # Inspect response_agent most recent message\n",
    "    if 'response_agent' in chunk:\n",
    "        chunk['response_agent']['messages'][-1].pretty_print()\n",
    "    # Inspect interrupt object if present\n",
    "    if '__interrupt__' in chunk:\n",
    "        Interrupt_Object = chunk['__interrupt__'][0]\n",
    "        print(\"\\nINTERRUPT OBJECT:\")\n",
    "        print(f\"Action Request: {Interrupt_Object.value[0]['action_request']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e214fe9e",
   "metadata": {},
   "source": [
    "Look at the full message history, and see the trace:\n",
    "\n",
    "https://smith.langchain.com/public/f4c727c3-b1d9-47a5-b3d0-3451619db8a2/r\n",
    "\n",
    "We can see that user feedback in incorporated into the email response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070393eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(thread_config_6)\n",
    "for m in state.values['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbec016-f08a-4984-abb9-07f428f5e69f",
   "metadata": {},
   "source": [
    "### Deployment\n",
    "\n",
    "Let's create a local deployment of our email assistant with HITL from `src/email_assistant/email_assistant_hitl.py`. \n",
    " \n",
    "As before, run `langgraph dev`, select `email_assistant_hitl` in Studio, and submit the e-mail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2609b7e4-2065-4641-a1e6-5960f399a5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"author\": \"Alice Smith <alice.smith@company.com>\",\n",
    "  \"to\": \"John Doe <john.doe@company.com>\",\n",
    "  \"subject\": \"Quick question about API documentation\",\n",
    "  \"email_thread\": \"Hi John,\\nI was reviewing the API documentation for the new authentication service and noticed a few endpoints seem to be missing from the specs. Could you help clarify if this was intentional or if we should update the docs?\\nSpecifically, I'm looking at:\\n- /auth/refresh\\n- /auth/validate\\nThanks!\\nAlice\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fe48f4",
   "metadata": {},
   "source": [
    "Our server it stateless. Threads with a local deployment are simply saved to the local filesystem (`.langgraph_api` in the project folder).\n",
    "\n",
    "With a [hosted](https://langchain-ai.github.io/langgraph/tutorials/deployment/#other-deployment-options) deployment, threads stored in Postgres.\n",
    "\n",
    "Interrupted threads are threads with status 'interrupted', and we can see the interrupt in Studio: \n",
    "\n",
    "![studio-img](img/studio-interrupt.png)\n",
    "\n",
    "We'll use a custom interface to view these interrupted threads, [Agent Inbox](https://dev.agentinbox.ai/). \n",
    "\n",
    "This interface is a nice way to edit, approve, ignore, or provide feedback on specific actions taken by LangGraph agents. \n",
    "\n",
    "If you go to [dev.agentinbox.ai](https://dev.agentinbox.ai/), you can easily connect to the graph:\n",
    "   * Graph name: the name from the `langgraph.json` file (`email_assistant_hitl`)\n",
    "   * Graph URL: `http://127.0.0.1:2024/`\n",
    "\n",
    "All interrupted threads run will then be visible: \n",
    "\n",
    "![agent-inbox-img](img/agent-inbox.png)\n",
    "\n",
    "Agent Inbox simply uses a `Command` with `resume`, as [shown with the SDK](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/wait-user-input/#interacting-with-the-agent) above, the resume the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd416e5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
